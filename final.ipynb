{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project: Sentences similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Team members:\n",
    "\n",
    "* Khanh Duong Tran.\n",
    "* Brandon."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Goal: Compare two sentences similarity by calculating Cosine similarity\n",
    "### Main ideas:\n",
    "\n",
    "#### 1. Vectorize the sentences.\n",
    "#### 2. Calculate Cosine similarity.\n",
    "#### 3. Compare the similarity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorize sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Cosine similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1]\n",
      "[0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split()\n",
    "    return words\n",
    "\n",
    "def create_vocabulary(sentences):\n",
    "    vocabulary = set()\n",
    "    for sentence in sentences:\n",
    "        words = preprocess_sentence(sentence)\n",
    "        vocabulary.update(words)\n",
    "    return {word: index for index, word in enumerate(vocabulary)}\n",
    "\n",
    "def vectorize_sentence(sentence, vocabulary):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    words = preprocess_sentence(sentence)\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            vector[vocabulary[word]] += 1\n",
    "    return vector\n",
    "\n",
    "sentences = [\"This is the first sentence.\", \"This is the second sentence.\"]\n",
    "vocabulary = create_vocabulary(sentences)\n",
    "\n",
    "vector1 = vectorize_sentence(sentences[0], vocabulary)\n",
    "vector2 = vectorize_sentence(sentences[1], vocabulary)\n",
    "\n",
    "print(vector1)\n",
    "print(vector2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremented element 2 due to word 'this'.\n",
      "Incremented element 1 due to word 'is'.\n",
      "Incremented element 5 due to word 'the'.\n",
      "Incremented element 0 due to word 'first'.\n",
      "Incremented element 3 due to word 'sentence'.\n",
      "Incremented element 2 due to word 'this'.\n",
      "Incremented element 1 due to word 'is'.\n",
      "Incremented element 5 due to word 'the'.\n",
      "Incremented element 4 due to word 'second'.\n",
      "Incremented element 3 due to word 'sentence'.\n",
      "[1, 1, 1, 1, 0, 1]\n",
      "[0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split()\n",
    "    return words\n",
    "\n",
    "def create_vocabulary(sentences):\n",
    "    vocabulary = set()\n",
    "    for sentence in sentences:\n",
    "        words = preprocess_sentence(sentence)\n",
    "        vocabulary.update(words)\n",
    "    return {word: index for index, word in enumerate(vocabulary)}\n",
    "\n",
    "def vectorize_sentence(sentence, vocabulary):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    words = preprocess_sentence(sentence)\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            vector[vocabulary[word]] += 1\n",
    "            print(f\"Incremented element {vocabulary[word]} due to word '{word}'.\")\n",
    "        else:\n",
    "            print(f\"Ignored word '{word}' as it is not in the vocabulary.\")\n",
    "    return vector\n",
    "\n",
    "sentences = [\"This is the first sentence.\", \"This is the second sentence.\"]\n",
    "vocabulary = create_vocabulary(sentences)\n",
    "\n",
    "vector1 = vectorize_sentence(sentences[0], vocabulary)\n",
    "vector2 = vectorize_sentence(sentences[1], vocabulary)\n",
    "\n",
    "print(vector1)\n",
    "print(vector2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
